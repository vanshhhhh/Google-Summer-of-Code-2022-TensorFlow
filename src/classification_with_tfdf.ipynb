{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgDUzWj1vFzr"
      },
      "source": [
        "# Classification with TensorFlow Decision Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iq75WIwvFzv"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "[TensorFlow Decision Forests](https://www.tensorflow.org/decision_forests)\n",
        "is a collection of state-of-the-art algorithms of Decision Forest models\n",
        "that are compatible with Keras APIs.\n",
        "The models include [Random Forests](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel),\n",
        "[Gradient Boosted Trees](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel),\n",
        "and [CART](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/CartModel),\n",
        "and can be used for regression, classification, and ranking task.\n",
        "For a beginner's guide to TensorFlow Decision Forests,\n",
        "please refer to this [tutorial](https://www.tensorflow.org/decision_forests/tutorials/beginner_colab).\n",
        "\n",
        "\n",
        "This example uses Gradient Boosted Trees model in binary classification of\n",
        "structured data, and covers the following scenarios:\n",
        "\n",
        "1. Build a decision forests model by specifying the input feature usage.\n",
        "2. Implement a custom *Binary Target encoder* as a [Keras Preprocessing layer](https://keras.io/api/layers/preprocessing_layers/)\n",
        "to encode the categorical features with respect to their target value co-occurrences,\n",
        "and then use the encoded features to build a decision forests model.\n",
        "3. Encode the categorical features as [embeddings](https://keras.io/api/layers/core_layers/embedding),\n",
        "train these embeddings in a simple NN model, and then use the\n",
        "trained embeddings as inputs to build decision forests model.\n",
        "\n",
        "This example uses TensorFlow 2.7 or higher,\n",
        "as well as [TensorFlow Decision Forests](https://www.tensorflow.org/decision_forests),\n",
        "which you can install using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow_decision_forests -U -q"
      ],
      "metadata": {
        "id": "wNCYW5RXxz1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qUh8WwvFzw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlDjCBCFvFzx"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_decision_forests as tfdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6RazPfvFzy"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "This example uses the\n",
        "[United States Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29)\n",
        "provided by the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).\n",
        "The task is binary classification to determine whether a person makes over 50K a year.\n",
        "\n",
        "The dataset includes ~300K instances with 41 input features: 7 numerical features\n",
        "and 34 categorical features.\n",
        "\n",
        "First we load the data from the UCI Machine Learning Repository into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY8TC4fwvFzz"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income\"\n",
        "CSV_HEADER = [\n",
        "    l.decode(\"utf-8\").split(\":\")[0].replace(\" \", \"_\")\n",
        "    for l in urllib.request.urlopen(f\"{BASE_PATH}.names\")\n",
        "    if not l.startswith(b\"|\")\n",
        "][2:]\n",
        "CSV_HEADER.append(\"income_level\")\n",
        "\n",
        "train_data = pd.read_csv(f\"{BASE_PATH}.data.gz\", header=None, names=CSV_HEADER,)\n",
        "test_data = pd.read_csv(f\"{BASE_PATH}.test.gz\", header=None, names=CSV_HEADER,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu_l7XHnvFzz"
      },
      "source": [
        "## Define dataset metadata\n",
        "\n",
        "Here, we define the metadata of the dataset that will be useful for encoding\n",
        "the input features with respect to their types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yK2GAoovFz0"
      },
      "outputs": [],
      "source": [
        "# Target column name.\n",
        "TARGET_COLUMN_NAME = \"income_level\"\n",
        "# The labels of the target columns.\n",
        "TARGET_LABELS = [\" - 50000.\", \" 50000+.\"]\n",
        "# Weight column name.\n",
        "WEIGHT_COLUMN_NAME = \"instance_weight\"\n",
        "# Numeric feature names.\n",
        "NUMERIC_FEATURE_NAMES = [\n",
        "    \"age\",\n",
        "    \"wage_per_hour\",\n",
        "    \"capital_gains\",\n",
        "    \"capital_losses\",\n",
        "    \"dividends_from_stocks\",\n",
        "    \"num_persons_worked_for_employer\",\n",
        "    \"weeks_worked_in_year\",\n",
        "]\n",
        "# Categorical features and their vocabulary lists.\n",
        "CATEGORICAL_FEATURE_NAMES = [\n",
        "    \"class_of_worker\",\n",
        "    \"detailed_industry_recode\",\n",
        "    \"detailed_occupation_recode\",\n",
        "    \"education\",\n",
        "    \"enroll_in_edu_inst_last_wk\",\n",
        "    \"marital_stat\",\n",
        "    \"major_industry_code\",\n",
        "    \"major_occupation_code\",\n",
        "    \"race\",\n",
        "    \"hispanic_origin\",\n",
        "    \"sex\",\n",
        "    \"member_of_a_labor_union\",\n",
        "    \"reason_for_unemployment\",\n",
        "    \"full_or_part_time_employment_stat\",\n",
        "    \"tax_filer_stat\",\n",
        "    \"region_of_previous_residence\",\n",
        "    \"state_of_previous_residence\",\n",
        "    \"detailed_household_and_family_stat\",\n",
        "    \"detailed_household_summary_in_household\",\n",
        "    \"migration_code-change_in_msa\",\n",
        "    \"migration_code-change_in_reg\",\n",
        "    \"migration_code-move_within_reg\",\n",
        "    \"live_in_this_house_1_year_ago\",\n",
        "    \"migration_prev_res_in_sunbelt\",\n",
        "    \"family_members_under_18\",\n",
        "    \"country_of_birth_father\",\n",
        "    \"country_of_birth_mother\",\n",
        "    \"country_of_birth_self\",\n",
        "    \"citizenship\",\n",
        "    \"own_business_or_self_employed\",\n",
        "    \"fill_inc_questionnaire_for_veteran's_admin\",\n",
        "    \"veterans_benefits\",\n",
        "    \"year\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW4opSlsvFz1"
      },
      "source": [
        "Now we perform basic data preparation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C48fK1YSvFz1"
      },
      "outputs": [],
      "source": [
        "def prepare_dataframe(dataframe):\n",
        "    # Convert the target labels from string to integer.\n",
        "    dataframe[TARGET_COLUMN_NAME] = dataframe[TARGET_COLUMN_NAME].map(\n",
        "        TARGET_LABELS.index\n",
        "    )\n",
        "    # Cast the categorical features to string.\n",
        "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "        dataframe[feature_name] = dataframe[feature_name].astype(str)\n",
        "\n",
        "\n",
        "prepare_dataframe(train_data)\n",
        "prepare_dataframe(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTgqDsmPvFz2"
      },
      "source": [
        "Now let's show the shapes of the training and test dataframes, and display some instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y4va4k0vFz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b019652-93f9-4734-b97e-3fac24bb21ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (199523, 42)\n",
            "Test data shape: (99762, 42)\n",
            "                                                                                    0  \\\n",
            "age                                                                                73   \n",
            "class_of_worker                                                       Not in universe   \n",
            "detailed_industry_recode                                                            0   \n",
            "detailed_occupation_recode                                                          0   \n",
            "education                                                        High school graduate   \n",
            "wage_per_hour                                                                       0   \n",
            "enroll_in_edu_inst_last_wk                                            Not in universe   \n",
            "marital_stat                                                                  Widowed   \n",
            "major_industry_code                                       Not in universe or children   \n",
            "major_occupation_code                                                 Not in universe   \n",
            "race                                                                            White   \n",
            "hispanic_origin                                                             All other   \n",
            "sex                                                                            Female   \n",
            "member_of_a_labor_union                                               Not in universe   \n",
            "reason_for_unemployment                                               Not in universe   \n",
            "full_or_part_time_employment_stat                                  Not in labor force   \n",
            "capital_gains                                                                       0   \n",
            "capital_losses                                                                      0   \n",
            "dividends_from_stocks                                                               0   \n",
            "tax_filer_stat                                                               Nonfiler   \n",
            "region_of_previous_residence                                          Not in universe   \n",
            "state_of_previous_residence                                           Not in universe   \n",
            "detailed_household_and_family_stat           Other Rel 18+ ever marr not in subfamily   \n",
            "detailed_household_summary_in_household                 Other relative of householder   \n",
            "instance_weight                                                               1700.09   \n",
            "migration_code-change_in_msa                                                        ?   \n",
            "migration_code-change_in_reg                                                        ?   \n",
            "migration_code-move_within_reg                                                      ?   \n",
            "live_in_this_house_1_year_ago                        Not in universe under 1 year old   \n",
            "migration_prev_res_in_sunbelt                                                       ?   \n",
            "num_persons_worked_for_employer                                                     0   \n",
            "family_members_under_18                                               Not in universe   \n",
            "country_of_birth_father                                                 United-States   \n",
            "country_of_birth_mother                                                 United-States   \n",
            "country_of_birth_self                                                   United-States   \n",
            "citizenship                                         Native- Born in the United States   \n",
            "own_business_or_self_employed                                                       0   \n",
            "fill_inc_questionnaire_for_veteran's_admin                            Not in universe   \n",
            "veterans_benefits                                                                   2   \n",
            "weeks_worked_in_year                                                                0   \n",
            "year                                                                               95   \n",
            "income_level                                                                        0   \n",
            "\n",
            "                                                                               1  \\\n",
            "age                                                                           58   \n",
            "class_of_worker                                   Self-employed-not incorporated   \n",
            "detailed_industry_recode                                                       4   \n",
            "detailed_occupation_recode                                                    34   \n",
            "education                                             Some college but no degree   \n",
            "wage_per_hour                                                                  0   \n",
            "enroll_in_edu_inst_last_wk                                       Not in universe   \n",
            "marital_stat                                                            Divorced   \n",
            "major_industry_code                                                 Construction   \n",
            "major_occupation_code                        Precision production craft & repair   \n",
            "race                                                                       White   \n",
            "hispanic_origin                                                        All other   \n",
            "sex                                                                         Male   \n",
            "member_of_a_labor_union                                          Not in universe   \n",
            "reason_for_unemployment                                          Not in universe   \n",
            "full_or_part_time_employment_stat                       Children or Armed Forces   \n",
            "capital_gains                                                                  0   \n",
            "capital_losses                                                                 0   \n",
            "dividends_from_stocks                                                          0   \n",
            "tax_filer_stat                                                 Head of household   \n",
            "region_of_previous_residence                                               South   \n",
            "state_of_previous_residence                                             Arkansas   \n",
            "detailed_household_and_family_stat                                   Householder   \n",
            "detailed_household_summary_in_household                              Householder   \n",
            "instance_weight                                                          1053.55   \n",
            "migration_code-change_in_msa                                          MSA to MSA   \n",
            "migration_code-change_in_reg                                         Same county   \n",
            "migration_code-move_within_reg                                       Same county   \n",
            "live_in_this_house_1_year_ago                                                 No   \n",
            "migration_prev_res_in_sunbelt                                                Yes   \n",
            "num_persons_worked_for_employer                                                1   \n",
            "family_members_under_18                                          Not in universe   \n",
            "country_of_birth_father                                            United-States   \n",
            "country_of_birth_mother                                            United-States   \n",
            "country_of_birth_self                                              United-States   \n",
            "citizenship                                    Native- Born in the United States   \n",
            "own_business_or_self_employed                                                  0   \n",
            "fill_inc_questionnaire_for_veteran's_admin                       Not in universe   \n",
            "veterans_benefits                                                              2   \n",
            "weeks_worked_in_year                                                          52   \n",
            "year                                                                          94   \n",
            "income_level                                                                   0   \n",
            "\n",
            "                                                                                   2  \\\n",
            "age                                                                               18   \n",
            "class_of_worker                                                      Not in universe   \n",
            "detailed_industry_recode                                                           0   \n",
            "detailed_occupation_recode                                                         0   \n",
            "education                                                                 10th grade   \n",
            "wage_per_hour                                                                      0   \n",
            "enroll_in_edu_inst_last_wk                                               High school   \n",
            "marital_stat                                                           Never married   \n",
            "major_industry_code                                      Not in universe or children   \n",
            "major_occupation_code                                                Not in universe   \n",
            "race                                                       Asian or Pacific Islander   \n",
            "hispanic_origin                                                            All other   \n",
            "sex                                                                           Female   \n",
            "member_of_a_labor_union                                              Not in universe   \n",
            "reason_for_unemployment                                              Not in universe   \n",
            "full_or_part_time_employment_stat                                 Not in labor force   \n",
            "capital_gains                                                                      0   \n",
            "capital_losses                                                                     0   \n",
            "dividends_from_stocks                                                              0   \n",
            "tax_filer_stat                                                              Nonfiler   \n",
            "region_of_previous_residence                                         Not in universe   \n",
            "state_of_previous_residence                                          Not in universe   \n",
            "detailed_household_and_family_stat           Child 18+ never marr Not in a subfamily   \n",
            "detailed_household_summary_in_household                            Child 18 or older   \n",
            "instance_weight                                                               991.95   \n",
            "migration_code-change_in_msa                                                       ?   \n",
            "migration_code-change_in_reg                                                       ?   \n",
            "migration_code-move_within_reg                                                     ?   \n",
            "live_in_this_house_1_year_ago                       Not in universe under 1 year old   \n",
            "migration_prev_res_in_sunbelt                                                      ?   \n",
            "num_persons_worked_for_employer                                                    0   \n",
            "family_members_under_18                                              Not in universe   \n",
            "country_of_birth_father                                                      Vietnam   \n",
            "country_of_birth_mother                                                      Vietnam   \n",
            "country_of_birth_self                                                        Vietnam   \n",
            "citizenship                                      Foreign born- Not a citizen of U S    \n",
            "own_business_or_self_employed                                                      0   \n",
            "fill_inc_questionnaire_for_veteran's_admin                           Not in universe   \n",
            "veterans_benefits                                                                  2   \n",
            "weeks_worked_in_year                                                               0   \n",
            "year                                                                              95   \n",
            "income_level                                                                       0   \n",
            "\n",
            "                                                                                 3  \\\n",
            "age                                                                              9   \n",
            "class_of_worker                                                    Not in universe   \n",
            "detailed_industry_recode                                                         0   \n",
            "detailed_occupation_recode                                                       0   \n",
            "education                                                                 Children   \n",
            "wage_per_hour                                                                    0   \n",
            "enroll_in_edu_inst_last_wk                                         Not in universe   \n",
            "marital_stat                                                         Never married   \n",
            "major_industry_code                                    Not in universe or children   \n",
            "major_occupation_code                                              Not in universe   \n",
            "race                                                                         White   \n",
            "hispanic_origin                                                          All other   \n",
            "sex                                                                         Female   \n",
            "member_of_a_labor_union                                            Not in universe   \n",
            "reason_for_unemployment                                            Not in universe   \n",
            "full_or_part_time_employment_stat                         Children or Armed Forces   \n",
            "capital_gains                                                                    0   \n",
            "capital_losses                                                                   0   \n",
            "dividends_from_stocks                                                            0   \n",
            "tax_filer_stat                                                            Nonfiler   \n",
            "region_of_previous_residence                                       Not in universe   \n",
            "state_of_previous_residence                                        Not in universe   \n",
            "detailed_household_and_family_stat           Child <18 never marr not in subfamily   \n",
            "detailed_household_summary_in_household               Child under 18 never married   \n",
            "instance_weight                                                            1758.14   \n",
            "migration_code-change_in_msa                                              Nonmover   \n",
            "migration_code-change_in_reg                                              Nonmover   \n",
            "migration_code-move_within_reg                                            Nonmover   \n",
            "live_in_this_house_1_year_ago                                                  Yes   \n",
            "migration_prev_res_in_sunbelt                                      Not in universe   \n",
            "num_persons_worked_for_employer                                                  0   \n",
            "family_members_under_18                                       Both parents present   \n",
            "country_of_birth_father                                              United-States   \n",
            "country_of_birth_mother                                              United-States   \n",
            "country_of_birth_self                                                United-States   \n",
            "citizenship                                      Native- Born in the United States   \n",
            "own_business_or_self_employed                                                    0   \n",
            "fill_inc_questionnaire_for_veteran's_admin                         Not in universe   \n",
            "veterans_benefits                                                                0   \n",
            "weeks_worked_in_year                                                             0   \n",
            "year                                                                            94   \n",
            "income_level                                                                     0   \n",
            "\n",
            "                                                                                 4  \n",
            "age                                                                             10  \n",
            "class_of_worker                                                    Not in universe  \n",
            "detailed_industry_recode                                                         0  \n",
            "detailed_occupation_recode                                                       0  \n",
            "education                                                                 Children  \n",
            "wage_per_hour                                                                    0  \n",
            "enroll_in_edu_inst_last_wk                                         Not in universe  \n",
            "marital_stat                                                         Never married  \n",
            "major_industry_code                                    Not in universe or children  \n",
            "major_occupation_code                                              Not in universe  \n",
            "race                                                                         White  \n",
            "hispanic_origin                                                          All other  \n",
            "sex                                                                         Female  \n",
            "member_of_a_labor_union                                            Not in universe  \n",
            "reason_for_unemployment                                            Not in universe  \n",
            "full_or_part_time_employment_stat                         Children or Armed Forces  \n",
            "capital_gains                                                                    0  \n",
            "capital_losses                                                                   0  \n",
            "dividends_from_stocks                                                            0  \n",
            "tax_filer_stat                                                            Nonfiler  \n",
            "region_of_previous_residence                                       Not in universe  \n",
            "state_of_previous_residence                                        Not in universe  \n",
            "detailed_household_and_family_stat           Child <18 never marr not in subfamily  \n",
            "detailed_household_summary_in_household               Child under 18 never married  \n",
            "instance_weight                                                            1069.16  \n",
            "migration_code-change_in_msa                                              Nonmover  \n",
            "migration_code-change_in_reg                                              Nonmover  \n",
            "migration_code-move_within_reg                                            Nonmover  \n",
            "live_in_this_house_1_year_ago                                                  Yes  \n",
            "migration_prev_res_in_sunbelt                                      Not in universe  \n",
            "num_persons_worked_for_employer                                                  0  \n",
            "family_members_under_18                                       Both parents present  \n",
            "country_of_birth_father                                              United-States  \n",
            "country_of_birth_mother                                              United-States  \n",
            "country_of_birth_self                                                United-States  \n",
            "citizenship                                      Native- Born in the United States  \n",
            "own_business_or_self_employed                                                    0  \n",
            "fill_inc_questionnaire_for_veteran's_admin                         Not in universe  \n",
            "veterans_benefits                                                                0  \n",
            "weeks_worked_in_year                                                             0  \n",
            "year                                                                            94  \n",
            "income_level                                                                     0  \n"
          ]
        }
      ],
      "source": [
        "print(f\"Train data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(train_data.head().T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW9XPqljvFz2"
      },
      "source": [
        "## Configure hyperparameters\n",
        "\n",
        "You can find all the parameters of the Gradient Boosted Tree model in the\n",
        "[documentation](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmlYHyTwvFz3"
      },
      "outputs": [],
      "source": [
        "# Maximum number of decision trees. The effective number of trained trees can be smaller if early stopping is enabled.\n",
        "NUM_TREES = 250\n",
        "# Minimum number of examples in a node.\n",
        "MIN_EXAMPLES = 6\n",
        "# Maximum depth of the tree. max_depth=1 means that all trees will be roots.\n",
        "MAX_DEPTH = 5\n",
        "# Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method.\n",
        "SUBSAMPLE = 0.65\n",
        "# Control the sampling of the datasets used to train individual trees.\n",
        "SAMPLING_METHOD = \"RANDOM\"\n",
        "# Ratio of the training dataset used to monitor the training. Require to be >0 if early stopping is enabled.\n",
        "VALIDATION_RATIO = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8XM-b8_vFz3"
      },
      "source": [
        "## Implement a training and evaluation procedure\n",
        "\n",
        "The `run_experiment()` method is responsible loading the train and test datasets,\n",
        "training a given model, and evaluating the trained model.\n",
        "\n",
        "Note that when training a Decision Forests model, only one epoch is needed to\n",
        "read the full dataset. Any extra steps will result in unnecessary slower training.\n",
        "Therefore, the default `num_epochs=1` is used in the `run_experiment()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8exQvsxmvFz3"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model, train_data, test_data, num_epochs=1, batch_size=None):\n",
        "    train_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "        train_data, label=TARGET_COLUMN_NAME, weight=WEIGHT_COLUMN_NAME\n",
        "    )\n",
        "    test_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "        test_data, label=TARGET_COLUMN_NAME, weight=WEIGHT_COLUMN_NAME\n",
        "    )\n",
        "    model.fit(train_dataset, epochs=num_epochs, batch_size=batch_size)\n",
        "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvVmo0cqvFz3"
      },
      "source": [
        "## Experiment 1: Decision Forests with raw features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL_cV_KJvFz4"
      },
      "source": [
        "### Specify model input feature usages\n",
        "\n",
        "You can attach semantics to each feature to control how it is used by the model.\n",
        "If not specified, the semantics are inferred from the representation type.\n",
        "It is recommended to specify the [feature usages](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/FeatureUsage)\n",
        "explicitly to avoid incorrect inferred semantics is incorrect.\n",
        "For example, a categorical value identifier (integer) will be be inferred as numerical,\n",
        "while it is semantically categorical.\n",
        "\n",
        "For numerical features, you can set the `discretized` parameters to the number\n",
        "of buckets by which the numerical feature should be discretized.\n",
        "This makes the training faster but may lead to worse models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g99xYA1zvFz4"
      },
      "outputs": [],
      "source": [
        "def specify_feature_usages():\n",
        "    feature_usages = []\n",
        "\n",
        "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
        "        feature_usage = tfdf.keras.FeatureUsage(\n",
        "            name=feature_name, semantic=tfdf.keras.FeatureSemantic.NUMERICAL\n",
        "        )\n",
        "        feature_usages.append(feature_usage)\n",
        "\n",
        "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "        feature_usage = tfdf.keras.FeatureUsage(\n",
        "            name=feature_name, semantic=tfdf.keras.FeatureSemantic.CATEGORICAL\n",
        "        )\n",
        "        feature_usages.append(feature_usage)\n",
        "\n",
        "    return feature_usages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cw22VbovFz4"
      },
      "source": [
        "### Create a Gradient Boosted Trees model\n",
        "\n",
        "When compiling a decision forests model, you may only provide extra evaluation metrics.\n",
        "The loss is specified in the model construction,\n",
        "and the optimizer is irrelevant to decision forests models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MEW9r5VvFz4"
      },
      "outputs": [],
      "source": [
        "def create_gbt_model():\n",
        "    # See all the model parameters in https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel\n",
        "    gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
        "        features=specify_feature_usages(),\n",
        "        exclude_non_specified_features=True,\n",
        "        num_trees=NUM_TREES,\n",
        "        max_depth=MAX_DEPTH,\n",
        "        min_examples=MIN_EXAMPLES,\n",
        "        subsample=SUBSAMPLE,\n",
        "        validation_ratio=VALIDATION_RATIO,\n",
        "        task=tfdf.keras.Task.CLASSIFICATION,\n",
        "    )\n",
        "    gbt_model.compile(metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
        "    return gbt_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWe7izedvFz5"
      },
      "source": [
        "### Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4qKgtO7vFz5"
      },
      "outputs": [],
      "source": [
        "gbt_model = create_gbt_model()\n",
        "run_experiment(gbt_model, train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQResFivFz5"
      },
      "source": [
        "### Inspect the model\n",
        "\n",
        "The `model.summary()` method will display several types of information about\n",
        "your decision trees model, model type, task, input features, and feature importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRJZIBu9vFz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c238938c-095d-417a-82ab-42fecda08a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"gradient_boosted_trees_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (40):\n",
            "\tage\n",
            "\tcapital_gains\n",
            "\tcapital_losses\n",
            "\tcitizenship\n",
            "\tclass_of_worker\n",
            "\tcountry_of_birth_father\n",
            "\tcountry_of_birth_mother\n",
            "\tcountry_of_birth_self\n",
            "\tdetailed_household_and_family_stat\n",
            "\tdetailed_household_summary_in_household\n",
            "\tdetailed_industry_recode\n",
            "\tdetailed_occupation_recode\n",
            "\tdividends_from_stocks\n",
            "\teducation\n",
            "\tenroll_in_edu_inst_last_wk\n",
            "\tfamily_members_under_18\n",
            "\tfill_inc_questionnaire_for_veteran's_admin\n",
            "\tfull_or_part_time_employment_stat\n",
            "\thispanic_origin\n",
            "\tlive_in_this_house_1_year_ago\n",
            "\tmajor_industry_code\n",
            "\tmajor_occupation_code\n",
            "\tmarital_stat\n",
            "\tmember_of_a_labor_union\n",
            "\tmigration_code-change_in_msa\n",
            "\tmigration_code-change_in_reg\n",
            "\tmigration_code-move_within_reg\n",
            "\tmigration_prev_res_in_sunbelt\n",
            "\tnum_persons_worked_for_employer\n",
            "\town_business_or_self_employed\n",
            "\trace\n",
            "\treason_for_unemployment\n",
            "\tregion_of_previous_residence\n",
            "\tsex\n",
            "\tstate_of_previous_residence\n",
            "\ttax_filer_stat\n",
            "\tveterans_benefits\n",
            "\twage_per_hour\n",
            "\tweeks_worked_in_year\n",
            "\tyear\n",
            "\n",
            "Trained with weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.                 \"enroll_in_edu_inst_last_wk\"  3.942647 ################\n",
            "    2.                    \"family_members_under_18\"  3.942647 ################\n",
            "    3.              \"live_in_this_house_1_year_ago\"  3.942647 ################\n",
            "    4.               \"migration_code-change_in_msa\"  3.942647 ################\n",
            "    5.             \"migration_code-move_within_reg\"  3.942647 ################\n",
            "    6.                                       \"year\"  3.942647 ################\n",
            "    7.                                    \"__LABEL\"  3.942647 ################\n",
            "    8.                                  \"__WEIGHTS\"  3.942647 ################\n",
            "    9.                                \"citizenship\"  3.942137 ###############\n",
            "   10.    \"detailed_household_summary_in_household\"  3.942137 ###############\n",
            "   11.               \"region_of_previous_residence\"  3.942137 ###############\n",
            "   12.                          \"veterans_benefits\"  3.942137 ###############\n",
            "   13.              \"migration_prev_res_in_sunbelt\"  3.940135 ###############\n",
            "   14.               \"migration_code-change_in_reg\"  3.939926 ###############\n",
            "   15.                      \"major_occupation_code\"  3.937681 ###############\n",
            "   16.                        \"major_industry_code\"  3.933687 ###############\n",
            "   17.                    \"reason_for_unemployment\"  3.926320 ###############\n",
            "   18.                            \"hispanic_origin\"  3.900776 ###############\n",
            "   19.                    \"member_of_a_labor_union\"  3.894843 ###############\n",
            "   20.                                       \"race\"  3.878617 ###############\n",
            "   21.            \"num_persons_worked_for_employer\"  3.818566 ##############\n",
            "   22.                               \"marital_stat\"  3.795667 ##############\n",
            "   23.          \"full_or_part_time_employment_stat\"  3.795431 ##############\n",
            "   24.                    \"country_of_birth_mother\"  3.787967 ##############\n",
            "   25.                             \"tax_filer_stat\"  3.784505 ##############\n",
            "   26. \"fill_inc_questionnaire_for_veteran's_admin\"  3.783607 ##############\n",
            "   27.              \"own_business_or_self_employed\"  3.776398 ##############\n",
            "   28.                    \"country_of_birth_father\"  3.715252 #############\n",
            "   29.                                        \"sex\"  3.708745 #############\n",
            "   30.                            \"class_of_worker\"  3.688424 #############\n",
            "   31.                       \"weeks_worked_in_year\"  3.665290 #############\n",
            "   32.                \"state_of_previous_residence\"  3.657234 #############\n",
            "   33.                      \"country_of_birth_self\"  3.654377 #############\n",
            "   34.                                        \"age\"  3.634295 ############\n",
            "   35.                              \"wage_per_hour\"  3.617817 ############\n",
            "   36.         \"detailed_household_and_family_stat\"  3.594743 ############\n",
            "   37.                             \"capital_losses\"  3.439298 ##########\n",
            "   38.                      \"dividends_from_stocks\"  3.423652 ##########\n",
            "   39.                              \"capital_gains\"  3.222753 ########\n",
            "   40.                                  \"education\"  3.158698 ########\n",
            "   41.                   \"detailed_industry_recode\"  2.981471 ######\n",
            "   42.                 \"detailed_occupation_recode\"  2.364817 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.                                  \"education\" 33.000000 ################\n",
            "    2.                              \"capital_gains\" 29.000000 ##############\n",
            "    3.                             \"capital_losses\" 24.000000 ###########\n",
            "    4.         \"detailed_household_and_family_stat\" 14.000000 ######\n",
            "    5.                      \"dividends_from_stocks\" 14.000000 ######\n",
            "    6.                              \"wage_per_hour\" 12.000000 #####\n",
            "    7.                      \"country_of_birth_self\" 11.000000 #####\n",
            "    8.                 \"detailed_occupation_recode\" 11.000000 #####\n",
            "    9.                       \"weeks_worked_in_year\" 11.000000 #####\n",
            "   10.                                        \"age\" 10.000000 ####\n",
            "   11.                \"state_of_previous_residence\" 10.000000 ####\n",
            "   12. \"fill_inc_questionnaire_for_veteran's_admin\"  9.000000 ####\n",
            "   13.                            \"class_of_worker\"  8.000000 ###\n",
            "   14.          \"full_or_part_time_employment_stat\"  8.000000 ###\n",
            "   15.                               \"marital_stat\"  8.000000 ###\n",
            "   16.              \"own_business_or_self_employed\"  8.000000 ###\n",
            "   17.                                        \"sex\"  6.000000 ##\n",
            "   18.                             \"tax_filer_stat\"  5.000000 ##\n",
            "   19.                    \"country_of_birth_father\"  4.000000 #\n",
            "   20.                                       \"race\"  3.000000 #\n",
            "   21.                   \"detailed_industry_recode\"  2.000000 \n",
            "   22.                            \"hispanic_origin\"  2.000000 \n",
            "   23.                    \"country_of_birth_mother\"  1.000000 \n",
            "   24.            \"num_persons_worked_for_employer\"  1.000000 \n",
            "   25.                    \"reason_for_unemployment\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.                 \"detailed_occupation_recode\" 785.000000 ################\n",
            "    2.                   \"detailed_industry_recode\" 668.000000 #############\n",
            "    3.                              \"capital_gains\" 275.000000 #####\n",
            "    4.                      \"dividends_from_stocks\" 220.000000 ####\n",
            "    5.                             \"capital_losses\" 197.000000 ####\n",
            "    6.                                  \"education\" 178.000000 ###\n",
            "    7.                    \"country_of_birth_mother\" 128.000000 ##\n",
            "    8.                    \"country_of_birth_father\" 116.000000 ##\n",
            "    9.                                        \"age\" 114.000000 ##\n",
            "   10.                              \"wage_per_hour\" 98.000000 #\n",
            "   11.                \"state_of_previous_residence\" 95.000000 #\n",
            "   12.         \"detailed_household_and_family_stat\" 78.000000 #\n",
            "   13.                            \"class_of_worker\" 67.000000 #\n",
            "   14.                      \"country_of_birth_self\" 65.000000 #\n",
            "   15.                                        \"sex\" 65.000000 #\n",
            "   16.                       \"weeks_worked_in_year\" 60.000000 #\n",
            "   17.                             \"tax_filer_stat\" 57.000000 #\n",
            "   18.            \"num_persons_worked_for_employer\" 54.000000 #\n",
            "   19.              \"own_business_or_self_employed\" 30.000000 \n",
            "   20.                               \"marital_stat\" 26.000000 \n",
            "   21.                    \"member_of_a_labor_union\" 16.000000 \n",
            "   22. \"fill_inc_questionnaire_for_veteran's_admin\" 15.000000 \n",
            "   23.          \"full_or_part_time_employment_stat\" 15.000000 \n",
            "   24.                        \"major_industry_code\" 15.000000 \n",
            "   25.                            \"hispanic_origin\"  9.000000 \n",
            "   26.                      \"major_occupation_code\"  7.000000 \n",
            "   27.                                       \"race\"  7.000000 \n",
            "   28.                                \"citizenship\"  1.000000 \n",
            "   29.    \"detailed_household_summary_in_household\"  1.000000 \n",
            "   30.               \"migration_code-change_in_reg\"  1.000000 \n",
            "   31.              \"migration_prev_res_in_sunbelt\"  1.000000 \n",
            "   32.                    \"reason_for_unemployment\"  1.000000 \n",
            "   33.               \"region_of_previous_residence\"  1.000000 \n",
            "   34.                          \"veterans_benefits\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.                 \"detailed_occupation_recode\" 15392441.075369 ################\n",
            "    2.                              \"capital_gains\" 5277826.822514 #####\n",
            "    3.                                  \"education\" 4751749.289550 ####\n",
            "    4.                      \"dividends_from_stocks\" 3792002.951255 ###\n",
            "    5.                   \"detailed_industry_recode\" 2882200.882109 ##\n",
            "    6.                                        \"sex\" 2559417.877325 ##\n",
            "    7.                                        \"age\" 2042990.944829 ##\n",
            "    8.                             \"capital_losses\" 1735728.772551 #\n",
            "    9.                       \"weeks_worked_in_year\" 1272820.203971 #\n",
            "   10.                             \"tax_filer_stat\" 697890.160846 \n",
            "   11.            \"num_persons_worked_for_employer\" 671351.905595 \n",
            "   12.         \"detailed_household_and_family_stat\" 444620.829557 \n",
            "   13.                            \"class_of_worker\" 362250.565331 \n",
            "   14.                    \"country_of_birth_mother\" 296311.574426 \n",
            "   15.                    \"country_of_birth_father\" 258198.889206 \n",
            "   16.                              \"wage_per_hour\" 239764.219048 \n",
            "   17.                \"state_of_previous_residence\" 237687.602572 \n",
            "   18.                      \"country_of_birth_self\" 103002.168158 \n",
            "   19.                               \"marital_stat\" 102449.735314 \n",
            "   20.              \"own_business_or_self_employed\" 82938.893541 \n",
            "   21. \"fill_inc_questionnaire_for_veteran's_admin\" 22692.700206 \n",
            "   22.          \"full_or_part_time_employment_stat\" 19078.398837 \n",
            "   23.                        \"major_industry_code\" 18450.345505 \n",
            "   24.                    \"member_of_a_labor_union\" 14905.360879 \n",
            "   25.                            \"hispanic_origin\" 12602.867902 \n",
            "   26.                      \"major_occupation_code\" 8709.665989 \n",
            "   27.                                       \"race\" 6116.282065 \n",
            "   28.                                \"citizenship\" 3291.490393 \n",
            "   29.    \"detailed_household_summary_in_household\" 2733.439375 \n",
            "   30.                          \"veterans_benefits\" 1230.940488 \n",
            "   31.               \"region_of_previous_residence\" 1139.240981 \n",
            "   32.                    \"reason_for_unemployment\" 219.245124 \n",
            "   33.               \"migration_code-change_in_reg\" 55.806436 \n",
            "   34.              \"migration_prev_res_in_sunbelt\" 37.780635 \n",
            "\n",
            "\n",
            "\n",
            "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
            "Validation loss value: 0.228983\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 245\n",
            "Total number of nodes: 7179\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 245 Average: 29.302 StdDev: 2.96211\n",
            "Min: 17 Max: 31 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 17, 18)   2   0.82%   0.82%\n",
            "[ 18, 19)   0   0.00%   0.82%\n",
            "[ 19, 20)   3   1.22%   2.04%\n",
            "[ 20, 21)   0   0.00%   2.04%\n",
            "[ 21, 22)   4   1.63%   3.67%\n",
            "[ 22, 23)   0   0.00%   3.67%\n",
            "[ 23, 24)  15   6.12%   9.80% #\n",
            "[ 24, 25)   0   0.00%   9.80%\n",
            "[ 25, 26)   5   2.04%  11.84%\n",
            "[ 26, 27)   0   0.00%  11.84%\n",
            "[ 27, 28)  21   8.57%  20.41% #\n",
            "[ 28, 29)   0   0.00%  20.41%\n",
            "[ 29, 30)  39  15.92%  36.33% ###\n",
            "[ 30, 31)   0   0.00%  36.33%\n",
            "[ 31, 31] 156  63.67% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 3712 Average: 3.95259 StdDev: 0.249814\n",
            "Min: 2 Max: 4 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 2, 3)   32   0.86%   0.86%\n",
            "[ 3, 4)  112   3.02%   3.88%\n",
            "[ 4, 4] 3568  96.12% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 3712 Average: 11849.3 StdDev: 33719.3\n",
            "Min: 6 Max: 179360 Ignored: 0\n",
            "----------------------------------------------\n",
            "[      6,   8973) 3100  83.51%  83.51% ##########\n",
            "[   8973,  17941)  148   3.99%  87.50%\n",
            "[  17941,  26909)   79   2.13%  89.63%\n",
            "[  26909,  35877)   36   0.97%  90.60%\n",
            "[  35877,  44844)   44   1.19%  91.78%\n",
            "[  44844,  53812)   17   0.46%  92.24%\n",
            "[  53812,  62780)   20   0.54%  92.78%\n",
            "[  62780,  71748)   39   1.05%  93.83%\n",
            "[  71748,  80715)   24   0.65%  94.48%\n",
            "[  80715,  89683)   12   0.32%  94.80%\n",
            "[  89683,  98651)   22   0.59%  95.39%\n",
            "[  98651, 107619)   21   0.57%  95.96%\n",
            "[ 107619, 116586)   17   0.46%  96.42%\n",
            "[ 116586, 125554)   17   0.46%  96.88%\n",
            "[ 125554, 134522)   13   0.35%  97.23%\n",
            "[ 134522, 143490)    8   0.22%  97.44%\n",
            "[ 143490, 152457)    5   0.13%  97.58%\n",
            "[ 152457, 161425)    6   0.16%  97.74%\n",
            "[ 161425, 170393)   15   0.40%  98.14%\n",
            "[ 170393, 179360]   69   1.86% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t668 : detailed_industry_recode [CATEGORICAL]\n",
            "\t275 : capital_gains [NUMERICAL]\n",
            "\t220 : dividends_from_stocks [NUMERICAL]\n",
            "\t197 : capital_losses [NUMERICAL]\n",
            "\t178 : education [CATEGORICAL]\n",
            "\t128 : country_of_birth_mother [CATEGORICAL]\n",
            "\t116 : country_of_birth_father [CATEGORICAL]\n",
            "\t114 : age [NUMERICAL]\n",
            "\t98 : wage_per_hour [NUMERICAL]\n",
            "\t95 : state_of_previous_residence [CATEGORICAL]\n",
            "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t67 : class_of_worker [CATEGORICAL]\n",
            "\t65 : sex [CATEGORICAL]\n",
            "\t65 : country_of_birth_self [CATEGORICAL]\n",
            "\t60 : weeks_worked_in_year [NUMERICAL]\n",
            "\t57 : tax_filer_stat [CATEGORICAL]\n",
            "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t26 : marital_stat [CATEGORICAL]\n",
            "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
            "\t15 : major_industry_code [CATEGORICAL]\n",
            "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t9 : hispanic_origin [CATEGORICAL]\n",
            "\t7 : race [CATEGORICAL]\n",
            "\t7 : major_occupation_code [CATEGORICAL]\n",
            "\t1 : veterans_benefits [CATEGORICAL]\n",
            "\t1 : region_of_previous_residence [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
            "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
            "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
            "\t1 : citizenship [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t33 : education [CATEGORICAL]\n",
            "\t29 : capital_gains [NUMERICAL]\n",
            "\t24 : capital_losses [NUMERICAL]\n",
            "\t14 : dividends_from_stocks [NUMERICAL]\n",
            "\t14 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t12 : wage_per_hour [NUMERICAL]\n",
            "\t11 : weeks_worked_in_year [NUMERICAL]\n",
            "\t11 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t11 : country_of_birth_self [CATEGORICAL]\n",
            "\t10 : state_of_previous_residence [CATEGORICAL]\n",
            "\t10 : age [NUMERICAL]\n",
            "\t9 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t8 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t8 : marital_stat [CATEGORICAL]\n",
            "\t8 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t8 : class_of_worker [CATEGORICAL]\n",
            "\t6 : sex [CATEGORICAL]\n",
            "\t5 : tax_filer_stat [CATEGORICAL]\n",
            "\t4 : country_of_birth_father [CATEGORICAL]\n",
            "\t3 : race [CATEGORICAL]\n",
            "\t2 : hispanic_origin [CATEGORICAL]\n",
            "\t2 : detailed_industry_recode [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\t1 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t1 : country_of_birth_mother [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t140 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t82 : capital_gains [NUMERICAL]\n",
            "\t65 : capital_losses [NUMERICAL]\n",
            "\t62 : education [CATEGORICAL]\n",
            "\t59 : detailed_industry_recode [CATEGORICAL]\n",
            "\t47 : dividends_from_stocks [NUMERICAL]\n",
            "\t31 : wage_per_hour [NUMERICAL]\n",
            "\t26 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t23 : age [NUMERICAL]\n",
            "\t22 : state_of_previous_residence [CATEGORICAL]\n",
            "\t21 : country_of_birth_self [CATEGORICAL]\n",
            "\t21 : class_of_worker [CATEGORICAL]\n",
            "\t20 : weeks_worked_in_year [NUMERICAL]\n",
            "\t20 : sex [CATEGORICAL]\n",
            "\t15 : country_of_birth_father [CATEGORICAL]\n",
            "\t12 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t11 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t10 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t9 : tax_filer_stat [CATEGORICAL]\n",
            "\t9 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t8 : marital_stat [CATEGORICAL]\n",
            "\t8 : country_of_birth_mother [CATEGORICAL]\n",
            "\t6 : member_of_a_labor_union [CATEGORICAL]\n",
            "\t5 : race [CATEGORICAL]\n",
            "\t2 : hispanic_origin [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t399 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t249 : detailed_industry_recode [CATEGORICAL]\n",
            "\t170 : capital_gains [NUMERICAL]\n",
            "\t117 : dividends_from_stocks [NUMERICAL]\n",
            "\t116 : capital_losses [NUMERICAL]\n",
            "\t87 : education [CATEGORICAL]\n",
            "\t59 : wage_per_hour [NUMERICAL]\n",
            "\t45 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t43 : country_of_birth_father [CATEGORICAL]\n",
            "\t43 : age [NUMERICAL]\n",
            "\t40 : country_of_birth_self [CATEGORICAL]\n",
            "\t38 : state_of_previous_residence [CATEGORICAL]\n",
            "\t38 : class_of_worker [CATEGORICAL]\n",
            "\t37 : sex [CATEGORICAL]\n",
            "\t36 : weeks_worked_in_year [NUMERICAL]\n",
            "\t33 : country_of_birth_mother [CATEGORICAL]\n",
            "\t28 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t26 : tax_filer_stat [CATEGORICAL]\n",
            "\t14 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t14 : marital_stat [CATEGORICAL]\n",
            "\t12 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t12 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t8 : member_of_a_labor_union [CATEGORICAL]\n",
            "\t6 : race [CATEGORICAL]\n",
            "\t6 : hispanic_origin [CATEGORICAL]\n",
            "\t2 : major_occupation_code [CATEGORICAL]\n",
            "\t2 : major_industry_code [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
            "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t668 : detailed_industry_recode [CATEGORICAL]\n",
            "\t275 : capital_gains [NUMERICAL]\n",
            "\t220 : dividends_from_stocks [NUMERICAL]\n",
            "\t197 : capital_losses [NUMERICAL]\n",
            "\t178 : education [CATEGORICAL]\n",
            "\t128 : country_of_birth_mother [CATEGORICAL]\n",
            "\t116 : country_of_birth_father [CATEGORICAL]\n",
            "\t114 : age [NUMERICAL]\n",
            "\t98 : wage_per_hour [NUMERICAL]\n",
            "\t95 : state_of_previous_residence [CATEGORICAL]\n",
            "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t67 : class_of_worker [CATEGORICAL]\n",
            "\t65 : sex [CATEGORICAL]\n",
            "\t65 : country_of_birth_self [CATEGORICAL]\n",
            "\t60 : weeks_worked_in_year [NUMERICAL]\n",
            "\t57 : tax_filer_stat [CATEGORICAL]\n",
            "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t26 : marital_stat [CATEGORICAL]\n",
            "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
            "\t15 : major_industry_code [CATEGORICAL]\n",
            "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t9 : hispanic_origin [CATEGORICAL]\n",
            "\t7 : race [CATEGORICAL]\n",
            "\t7 : major_occupation_code [CATEGORICAL]\n",
            "\t1 : veterans_benefits [CATEGORICAL]\n",
            "\t1 : region_of_previous_residence [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
            "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
            "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
            "\t1 : citizenship [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
            "\t668 : detailed_industry_recode [CATEGORICAL]\n",
            "\t275 : capital_gains [NUMERICAL]\n",
            "\t220 : dividends_from_stocks [NUMERICAL]\n",
            "\t197 : capital_losses [NUMERICAL]\n",
            "\t178 : education [CATEGORICAL]\n",
            "\t128 : country_of_birth_mother [CATEGORICAL]\n",
            "\t116 : country_of_birth_father [CATEGORICAL]\n",
            "\t114 : age [NUMERICAL]\n",
            "\t98 : wage_per_hour [NUMERICAL]\n",
            "\t95 : state_of_previous_residence [CATEGORICAL]\n",
            "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
            "\t67 : class_of_worker [CATEGORICAL]\n",
            "\t65 : sex [CATEGORICAL]\n",
            "\t65 : country_of_birth_self [CATEGORICAL]\n",
            "\t60 : weeks_worked_in_year [NUMERICAL]\n",
            "\t57 : tax_filer_stat [CATEGORICAL]\n",
            "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
            "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
            "\t26 : marital_stat [CATEGORICAL]\n",
            "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
            "\t15 : major_industry_code [CATEGORICAL]\n",
            "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
            "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
            "\t9 : hispanic_origin [CATEGORICAL]\n",
            "\t7 : race [CATEGORICAL]\n",
            "\t7 : major_occupation_code [CATEGORICAL]\n",
            "\t1 : veterans_benefits [CATEGORICAL]\n",
            "\t1 : region_of_previous_residence [CATEGORICAL]\n",
            "\t1 : reason_for_unemployment [CATEGORICAL]\n",
            "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
            "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
            "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
            "\t1 : citizenship [CATEGORICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t2418 : ContainsBitmapCondition\n",
            "\t1018 : HigherCondition\n",
            "\t31 : ContainsCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t137 : ContainsBitmapCondition\n",
            "\t101 : HigherCondition\n",
            "\t7 : ContainsCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t448 : ContainsBitmapCondition\n",
            "\t278 : HigherCondition\n",
            "\t9 : ContainsCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1097 : ContainsBitmapCondition\n",
            "\t569 : HigherCondition\n",
            "\t17 : ContainsCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2418 : ContainsBitmapCondition\n",
            "\t1018 : HigherCondition\n",
            "\t31 : ContainsCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t2418 : ContainsBitmapCondition\n",
            "\t1018 : HigherCondition\n",
            "\t31 : ContainsCondition\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(gbt_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6hd_wcXvFz6"
      },
      "source": [
        "## Experiment 2: Decision Forests with target encoding\n",
        "\n",
        "[Target encoding](https://dl.acm.org/doi/10.1145/507533.507538) is a common preprocessing\n",
        "technique for categorical features that convert them into numerical features.\n",
        "Using categorical features with high cardinality as-is may lead to overfitting.\n",
        "Target encoding aims to replace each categorical feature value with one or more\n",
        "numerical values that represent its co-occurrence with the target labels.\n",
        "\n",
        "More precisely, given a categorical feature, the binary target encoder in this example\n",
        "will produce three new numerical features:\n",
        "\n",
        "1. `positive_frequency`: How many times each feature value occurred with a positive target label.\n",
        "2. `negative_frequency`: How many times each feature value occurred with a negative target label.\n",
        "3. `positive_probability`: The probability that the target label is positive,\n",
        "given the feature value, which is computed as\n",
        "`positive_frequency / (positive_frequency + negative_frequency + correction)`.\n",
        "The `correction` term is added in to make the division more stable for rare categorical values.\n",
        "The default value for `correction` is 1.0.\n",
        "\n",
        "\n",
        "\n",
        "Note that target encoding is effective with models that cannot automatically\n",
        "learn dense representations to categorical features, such as decision forests\n",
        "or kernel methods. If neural network models are used, its recommended to\n",
        "encode categorical features as embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDvEEWx2vFz6"
      },
      "source": [
        "### Implement Binary Target Encoder\n",
        "\n",
        "For simplicity, we assume that the inputs for the `adapt` and `call` methods\n",
        "are in the expected data types and shapes, so no validation logic is added.\n",
        "\n",
        "It is recommended to pass the `vocabulary_size` of the categorical feature to the\n",
        "`BinaryTargetEncoding` constructor. If not specified, it will be computed during\n",
        "the `adapt()` method execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leC5DSH3vFz6"
      },
      "outputs": [],
      "source": [
        "class BinaryTargetEncoding(layers.Layer):\n",
        "    def __init__(self, vocabulary_size=None, correction=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "        self.correction = correction\n",
        "\n",
        "    def adapt(self, data):\n",
        "        # data is expected to be an integer numpy array to a Tensor shape [num_exmples, 2].\n",
        "        # This contains feature values for a given feature in the dataset, and target values.\n",
        "\n",
        "        # Convert the data to a tensor.\n",
        "        data = tf.convert_to_tensor(data)\n",
        "        # Separate the feature values and target values\n",
        "        feature_values = tf.cast(data[:, 0], tf.dtypes.int32)\n",
        "        target_values = tf.cast(data[:, 1], tf.dtypes.bool)\n",
        "\n",
        "        # Compute the vocabulary_size of not specified.\n",
        "        if self.vocabulary_size is None:\n",
        "            self.vocabulary_size = tf.unique(feature_values).y.shape[0]\n",
        "\n",
        "        # Filter the data where the target label is positive.\n",
        "        positive_indices = tf.where(condition=target_values)\n",
        "        postive_feature_values = tf.gather_nd(\n",
        "            params=feature_values, indices=positive_indices\n",
        "        )\n",
        "        # Compute how many times each feature value occurred with a positive target label.\n",
        "        positive_frequency = tf.math.unsorted_segment_sum(\n",
        "            data=tf.ones(\n",
        "                shape=(postive_feature_values.shape[0], 1), dtype=tf.dtypes.float64\n",
        "            ),\n",
        "            segment_ids=postive_feature_values,\n",
        "            num_segments=self.vocabulary_size,\n",
        "        )\n",
        "\n",
        "        # Filter the data where the target label is negative.\n",
        "        negative_indices = tf.where(condition=tf.math.logical_not(target_values))\n",
        "        negative_feature_values = tf.gather_nd(\n",
        "            params=feature_values, indices=negative_indices\n",
        "        )\n",
        "        # Compute how many times each feature value occurred with a negative target label.\n",
        "        negative_frequency = tf.math.unsorted_segment_sum(\n",
        "            data=tf.ones(\n",
        "                shape=(negative_feature_values.shape[0], 1), dtype=tf.dtypes.float64\n",
        "            ),\n",
        "            segment_ids=negative_feature_values,\n",
        "            num_segments=self.vocabulary_size,\n",
        "        )\n",
        "        # Compute positive probability for the input feature values.\n",
        "        positive_probability = positive_frequency / (\n",
        "            positive_frequency + negative_frequency + self.correction\n",
        "        )\n",
        "        # Concatenate the computed statistics for traget_encoding.\n",
        "        target_encoding_statistics = tf.cast(\n",
        "            tf.concat(\n",
        "                [positive_frequency, negative_frequency, positive_probability], axis=1\n",
        "            ),\n",
        "            dtype=tf.dtypes.float32,\n",
        "        )\n",
        "        self.target_encoding_statistics = tf.constant(target_encoding_statistics)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs is expected to be an integer numpy array to a Tensor shape [num_exmples, 1].\n",
        "        # This includes the feature values for a given feature in the dataset.\n",
        "\n",
        "        # Raise an error if the target encoding statistics are not computed.\n",
        "        if self.target_encoding_statistics == None:\n",
        "            raise ValueError(\n",
        "                f\"You need to call the adapt method to compute target encoding statistics.\"\n",
        "            )\n",
        "\n",
        "        # Convert the inputs to a tensor.\n",
        "        inputs = tf.convert_to_tensor(inputs)\n",
        "        # Cast the inputs int64 a tensor.\n",
        "        inputs = tf.cast(inputs, tf.dtypes.int64)\n",
        "        # Lookup target encoding statistics for the input feature values.\n",
        "        target_encoding_statistics = tf.cast(\n",
        "            tf.gather_nd(self.target_encoding_statistics, inputs),\n",
        "            dtype=tf.dtypes.float32,\n",
        "        )\n",
        "        return target_encoding_statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbdgeTjivFz7"
      },
      "source": [
        "Let's test the binary target encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b9qfKCNvFz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af21c966-00e6-4b92-e9b7-bf4751348610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[6.         0.         0.85714287]\n",
            " [4.         3.         0.5       ]\n",
            " [1.         5.         0.14285715]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "data = tf.constant(\n",
        "    [\n",
        "        [0, 1],\n",
        "        [2, 0],\n",
        "        [0, 1],\n",
        "        [1, 1],\n",
        "        [1, 1],\n",
        "        [2, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [2, 1],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [2, 0],\n",
        "        [0, 1],\n",
        "        [1, 1],\n",
        "        [1, 1],\n",
        "        [2, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [2, 0],\n",
        "    ]\n",
        ")\n",
        "\n",
        "binary_target_encoder = BinaryTargetEncoding()\n",
        "binary_target_encoder.adapt(data)\n",
        "print(binary_target_encoder([[0], [1], [2]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zi1LhmCvFz7"
      },
      "source": [
        "### Create model inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HySU7zXIvFz7"
      },
      "outputs": [],
      "source": [
        "def create_model_inputs():\n",
        "    inputs = {}\n",
        "\n",
        "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
        "        inputs[feature_name] = layers.Input(\n",
        "            name=feature_name, shape=(), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "        inputs[feature_name] = layers.Input(\n",
        "            name=feature_name, shape=(), dtype=tf.string\n",
        "        )\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBeO5zGkvFz7"
      },
      "source": [
        "### Implement a feature encoding with target encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQW474_0vFz8"
      },
      "outputs": [],
      "source": [
        "def create_target_encoder():\n",
        "    inputs = create_model_inputs()\n",
        "    target_values = train_data[[TARGET_COLUMN_NAME]].to_numpy()\n",
        "    encoded_features = []\n",
        "    for feature_name in inputs:\n",
        "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "            # Get the vocabulary of the categorical feature.\n",
        "            vocabulary = sorted(\n",
        "                [str(value) for value in list(train_data[feature_name].unique())]\n",
        "            )\n",
        "            # Create a lookup to convert string values to an integer indices.\n",
        "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
        "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
        "            lookup = layers.StringLookup(\n",
        "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
        "            )\n",
        "            # Convert the string input values into integer indices.\n",
        "            value_indices = lookup(inputs[feature_name])\n",
        "            # Prepare the data to adapt the target encoding.\n",
        "            print(\"### Adapting target encoding for:\", feature_name)\n",
        "            feature_values = train_data[[feature_name]].to_numpy().astype(str)\n",
        "            feature_value_indices = lookup(feature_values)\n",
        "            data = tf.concat([feature_value_indices, target_values], axis=1)\n",
        "            feature_encoder = BinaryTargetEncoding()\n",
        "            feature_encoder.adapt(data)\n",
        "            # Convert the feature value indices to target encoding representations.\n",
        "            encoded_feature = feature_encoder(tf.expand_dims(value_indices, -1))\n",
        "        else:\n",
        "            # Expand the dimensions of the numerical input feature and use it as-is.\n",
        "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
        "        # Add the encoded feature to the list.\n",
        "        encoded_features.append(encoded_feature)\n",
        "    # Concatenate all the encoded features.\n",
        "    encoded_features = tf.concat(encoded_features, axis=1)\n",
        "    # Create and return a Keras model with encoded features as outputs.\n",
        "    return keras.Model(inputs=inputs, outputs=encoded_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM42o_5vvFz8"
      },
      "source": [
        "### Create a Gradient Boosted Trees model with a preprocessor\n",
        "\n",
        "In this scenario, we use the target encoding as a preprocessor for the Gradient Boosted Tree model,\n",
        "and let the model infer semantics of the input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfwvdL4DvFz8"
      },
      "outputs": [],
      "source": [
        "def create_gbt_with_preprocessor(preprocessor):\n",
        "\n",
        "    gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
        "        preprocessing=preprocessor,\n",
        "        num_trees=NUM_TREES,\n",
        "        max_depth=MAX_DEPTH,\n",
        "        min_examples=MIN_EXAMPLES,\n",
        "        subsample=SUBSAMPLE,\n",
        "        validation_ratio=VALIDATION_RATIO,\n",
        "        task=tfdf.keras.Task.CLASSIFICATION,\n",
        "    )\n",
        "\n",
        "    gbt_model.compile(metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
        "\n",
        "    return gbt_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjexsX1UvFz8"
      },
      "source": [
        "### Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uzb9Pp3vvFz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b1caa6-739a-4211-f653-e3389c5f3245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  return bool(asarray(a1 == a2).all())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Adapting target encoding for: class_of_worker\n",
            "### Adapting target encoding for: detailed_industry_recode\n",
            "### Adapting target encoding for: detailed_occupation_recode\n",
            "### Adapting target encoding for: education\n",
            "### Adapting target encoding for: enroll_in_edu_inst_last_wk\n",
            "### Adapting target encoding for: marital_stat\n",
            "### Adapting target encoding for: major_industry_code\n",
            "### Adapting target encoding for: major_occupation_code\n",
            "### Adapting target encoding for: race\n",
            "### Adapting target encoding for: hispanic_origin\n",
            "### Adapting target encoding for: sex\n",
            "### Adapting target encoding for: member_of_a_labor_union\n",
            "### Adapting target encoding for: reason_for_unemployment\n",
            "### Adapting target encoding for: full_or_part_time_employment_stat\n",
            "### Adapting target encoding for: tax_filer_stat\n",
            "### Adapting target encoding for: region_of_previous_residence\n",
            "### Adapting target encoding for: state_of_previous_residence\n",
            "### Adapting target encoding for: detailed_household_and_family_stat\n",
            "### Adapting target encoding for: detailed_household_summary_in_household\n",
            "### Adapting target encoding for: migration_code-change_in_msa\n",
            "### Adapting target encoding for: migration_code-change_in_reg\n",
            "### Adapting target encoding for: migration_code-move_within_reg\n",
            "### Adapting target encoding for: live_in_this_house_1_year_ago\n",
            "### Adapting target encoding for: migration_prev_res_in_sunbelt\n",
            "### Adapting target encoding for: family_members_under_18\n",
            "### Adapting target encoding for: country_of_birth_father\n",
            "### Adapting target encoding for: country_of_birth_mother\n",
            "### Adapting target encoding for: country_of_birth_self\n",
            "### Adapting target encoding for: citizenship\n",
            "### Adapting target encoding for: own_business_or_self_employed\n",
            "### Adapting target encoding for: fill_inc_questionnaire_for_veteran's_admin\n",
            "### Adapting target encoding for: veterans_benefits\n",
            "### Adapting target encoding for: year\n",
            "Use /tmp/tmp005zsgb9 as temporary training directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2542: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2545: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = features_dataframe.drop(weight, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:08.133058. Found 199523 examples.\n",
            "Training model...\n",
            "Model trained in 0:10:38.017651\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 95.81%\n"
          ]
        }
      ],
      "source": [
        "gbt_model = create_gbt_with_preprocessor(create_target_encoder())\n",
        "run_experiment(gbt_model, train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDAs-_hQvFz9"
      },
      "source": [
        "## Experiment 3: Decision Forests with trained embeddings\n",
        "\n",
        "In this scenario, we build an encoder model that codes the categorical\n",
        "features to embeddings, where the size of the embedding for a given categorical\n",
        "feature is the square root to the size of its vocabulary.\n",
        "\n",
        "We train these embeddings in a simple NN model through backpropagation.\n",
        "After the embedding encoder is trained, we used it as a preprocessor to the\n",
        "input features of a Gradient Boosted Tree model.\n",
        "\n",
        "Note that the embeddings and a decision forest model cannot be trained\n",
        "synergically in one phase, since decision forest models do not train with backpropagation.\n",
        "Rather, embeddings has to be trained in an initial phase,\n",
        "and then used as static inputs to the decision forest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tExD47sGvFz9"
      },
      "source": [
        "### Implement feature encoding with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK6FzicsvFz9"
      },
      "outputs": [],
      "source": [
        "def create_embedding_encoder(size=None):\n",
        "    inputs = create_model_inputs()\n",
        "    encoded_features = []\n",
        "    for feature_name in inputs:\n",
        "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "            # Get the vocabulary of the categorical feature.\n",
        "            vocabulary = sorted(\n",
        "                [str(value) for value in list(train_data[feature_name].unique())]\n",
        "            )\n",
        "            # Create a lookup to convert string values to an integer indices.\n",
        "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
        "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
        "            lookup = layers.StringLookup(\n",
        "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
        "            )\n",
        "            # Convert the string input values into integer indices.\n",
        "            value_index = lookup(inputs[feature_name])\n",
        "            # Create an embedding layer with the specified dimensions\n",
        "            vocabulary_size = len(vocabulary)\n",
        "            embedding_size = int(math.sqrt(vocabulary_size))\n",
        "            feature_encoder = layers.Embedding(\n",
        "                input_dim=len(vocabulary), output_dim=embedding_size\n",
        "            )\n",
        "            # Convert the index values to embedding representations.\n",
        "            encoded_feature = feature_encoder(value_index)\n",
        "        else:\n",
        "            # Expand the dimensions of the numerical input feature and use it as-is.\n",
        "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
        "        # Add the encoded feature to the list.\n",
        "        encoded_features.append(encoded_feature)\n",
        "    # Concatenate all the encoded features.\n",
        "    encoded_features = layers.concatenate(encoded_features, axis=1)\n",
        "    # Apply dropout.\n",
        "    encoded_features = layers.Dropout(rate=0.25)(encoded_features)\n",
        "    # Perform non-linearity projection.\n",
        "    encoded_features = layers.Dense(\n",
        "        units=size if size else encoded_features.shape[-1], activation=\"gelu\"\n",
        "    )(encoded_features)\n",
        "    # Create and return a Keras model with encoded features as outputs.\n",
        "    return keras.Model(inputs=inputs, outputs=encoded_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJhaLCakvFz9"
      },
      "source": [
        "### Build an NN model to train the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIYHzTYovFz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94dbf90e-1316-4361-badb-d82b1272947e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  return bool(asarray(a1 == a2).all())\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2542: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2545: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = features_dataframe.drop(weight, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 12s 33ms/step - loss: 2663.1277 - accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 968.8642 - accuracy: 0.9353\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 6s 32ms/step - loss: 941.5861 - accuracy: 0.9374\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 916.6326 - accuracy: 0.9393\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 6s 32ms/step - loss: 664.7021 - accuracy: 0.9415\n",
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 94.87%\n"
          ]
        }
      ],
      "source": [
        "def create_nn_model(encoder):\n",
        "    inputs = create_model_inputs()\n",
        "    embeddings = encoder(inputs)\n",
        "    output = layers.Dense(units=1, activation=\"sigmoid\")(embeddings)\n",
        "\n",
        "    nn_model = keras.Model(inputs=inputs, outputs=output)\n",
        "    nn_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[keras.metrics.BinaryAccuracy(\"accuracy\")],\n",
        "    )\n",
        "    return nn_model\n",
        "\n",
        "\n",
        "embedding_encoder = create_embedding_encoder(size=64)\n",
        "run_experiment(\n",
        "    create_nn_model(embedding_encoder),\n",
        "    train_data,\n",
        "    test_data,\n",
        "    num_epochs=5,\n",
        "    batch_size=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwrpG1tQvFz-"
      },
      "source": [
        "### Train and evaluate a Gradient Boosted Tree model with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS-ZaB1FvFz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2347545a-39f9-49fc-8936-9ff15f512cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpoi2vjjwx as temporary training directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2542: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2545: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = features_dataframe.drop(weight, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:06.102465. Found 199523 examples.\n",
            "Training model...\n",
            "Model trained in 0:11:51.297584\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 95.32%\n"
          ]
        }
      ],
      "source": [
        "gbt_model = create_gbt_with_preprocessor(embedding_encoder)\n",
        "run_experiment(gbt_model, train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX_OIJqzvFz-"
      },
      "source": [
        "## Concluding remarks\n",
        "\n",
        "TensorFlow Decision Forests provide powerful models, especially with structured data.\n",
        "In our experiments, the Gradient Boosted Tree model achieved 95.81% test accuracy.\n",
        "When using the target encoding with categorical feature, the same model achieved 95.81% test accuracy.\n",
        "When pretraining embeddings to be used as inputs to the Gradient Boosted Tree model,\n",
        "we achieved 95.32% test accuracy.\n",
        "\n",
        "Decision Forests can be used with Neural Networks, either by\n",
        "1) using Neural Networks to learn useful representation of the input data,\n",
        "and then using Decision Forests for the supervised learning task, or by\n",
        "2) creating an ensemble of both Decision Forests and Neural Network models.\n",
        "\n",
        "Note that TensorFlow Decision Forests does not (yet) support hardware accelerators.\n",
        "All training and inference is done on the CPU.\n",
        "Besides, Decision Forests require a finite dataset that fits in memory\n",
        "for their training procedures. However, there are diminishing returns\n",
        "for increasing the size of the dataset, and Decision Forests algorithms\n",
        "arguably need fewer examples for convergence than large Neural Network models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}